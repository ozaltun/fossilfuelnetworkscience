{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import pyipopt\n",
    "from autograd import grad, hessian, jacobian\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from counterfactual_functions import *\n",
    "from helper import *\n",
    "\n",
    "\n",
    "\n",
    "username='boraozaltun'\n",
    "\n",
    "data_dict = load_obj('/Users/'+username+'/Dropbox (MIT)/Data/Trade/general_equilibrium_gravity/final_data/data_subset_20200304.pickle')\n",
    "\n",
    "reg_2_num = load_obj('/Users/'+username+'/Dropbox (MIT)/Data/Trade/general_equilibrium_gravity/GTAP/mapping/reg_2_num.pickle')\n",
    "comm_2_num = load_obj('/Users/'+username+'/Dropbox (MIT)/Data/Trade/general_equilibrium_gravity/GTAP/mapping/comm_2_num.pickle')\n",
    "\n",
    "\n",
    "def eval_jac_g(X, flag, user_data=None):\n",
    "    \"\"\"\n",
    "    Evaluate the sparse Jacobian of constraint functions g.\n",
    "    @param X: parameter values\n",
    "    @param flag: this asks for the sparsity structure\n",
    "    \"\"\"\n",
    "    print('eval_jac_g')\n",
    "\n",
    "    if flag:\n",
    "        temp = np.ones((X.shape[0], X.shape[0]))\n",
    "        rows, cols = np.nonzero(temp)\n",
    "        #rows = np.linspace(0, len(X) -1, len(X)).astype(int)\n",
    "        #cols = np.linspace(0, len(X) -1, len(X)).astype(int)\n",
    "        return (rows, cols)\n",
    "    else:\n",
    "\n",
    "        return jac_g(X)\n",
    "\n",
    "\n",
    "n = data_dict['n']\n",
    "g = data_dict['g']\n",
    "k = data_dict['k']\n",
    "\n",
    "data_dict['R_hat'] = np.ones((n, g))\n",
    "data_dict['R_hat'][reg_2_num['usa'], 3] = 1.2\n",
    "data_dict['R_hat'][reg_2_num['usa'], 4] = 1.2\n",
    "\n",
    "\n",
    "\n",
    "X_0 = np.ones(n*g + n)*1.0\n",
    "\n",
    "eval_g = lambda x: reduced_counterfactual(x, data_dict)\n",
    "eval_f = lambda x: np.linalg.norm(reduced_counterfactual(x, data_dict))\n",
    "\n",
    "jac_g = jacobian(eval_g)\n",
    "nvar = X_0.shape[0]\n",
    "x_L = np.zeros((nvar))\n",
    "x_U = np.ones((nvar)) * 10000.0\n",
    "\n",
    "ncon = nvar\n",
    "\n",
    "g_L = np.zeros((nvar))*1.0\n",
    "g_U = np.zeros((nvar))*1.0\n",
    "\n",
    "eval_grad_f = grad(eval_f)\n",
    "\n",
    "nnzj = nvar*nvar\n",
    "nnzh =  int((nvar*(nvar+1))/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/numpy/numpy_vjps.py:444: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return lambda g: g[idxs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.52755188e-01,  1.00111107e-03, -1.46339193e-03, ...,\n",
       "        -1.46929004e-02, -7.28881710e-05, -4.76069843e-06],\n",
       "       [-7.64187159e-04,  7.79623440e-01, -2.33400695e-03, ...,\n",
       "        -1.47474365e-02, -2.57801718e-03, -5.21148209e-06],\n",
       "       [-1.10591706e-03, -4.43783516e-03,  2.24200119e+00, ...,\n",
       "        -3.79250284e-02, -4.18632515e-05, -2.81291510e-06],\n",
       "       ...,\n",
       "       [-1.84837256e-04, -6.88145491e-04, -1.34014400e-03, ...,\n",
       "         1.04578445e+00, -1.46816159e-03, -2.38601264e-06],\n",
       "       [-1.44478075e-04, -8.37514598e-03, -6.30256125e-04, ...,\n",
       "        -1.23438870e-01,  2.46370222e+00, -1.94664769e-06],\n",
       "       [-1.63606559e-04, -6.18582026e-04, -6.53421152e-04, ...,\n",
       "        -6.65856827e-03, -7.86470556e-05,  1.26055739e+00]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac_g(X_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pyipopt.create(\n",
    "            nvar,\n",
    "            x_L,\n",
    "            x_U,\n",
    "            ncon,\n",
    "            g_L,\n",
    "            g_U,\n",
    "            nnzj,\n",
    "            nnzh,\n",
    "            eval_f,\n",
    "            eval_grad_f,\n",
    "            eval_g,\n",
    "            eval_jac_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_jac_g\n",
      "eval_jac_g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/numpy/numpy_vjps.py:444: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return lambda g: g[idxs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n",
      "eval_jac_g\n"
     ]
    }
   ],
   "source": [
    "x, zl, zu, constraint_multipliers, obj, status = nlp.solve(X_0)\n",
    "\n",
    "print('x:', x)\n",
    "print('zl:', zl)\n",
    "print('zu:', zu)\n",
    "print('constraint_multipliers:', constraint_multipliers)\n",
    "print('obj:', obj)\n",
    "print('status:', status)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
